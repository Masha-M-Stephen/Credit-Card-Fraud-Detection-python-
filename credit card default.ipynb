{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT: CREDIT CARD DEFAULT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center for Machine Learning and Intelligent Systems\n",
    "\n",
    "Default of credit card clients Data Set\n",
    "Download: Data Folder, Data Set Description\n",
    "\n",
    "Abstract: This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.\n",
    "\n",
    "Data Set Characteristics:  Multivariate\n",
    "\n",
    "Number of Instances: 30000\n",
    "\n",
    "Area: Business\n",
    "\n",
    "Attribute Characteristics: Integer, Real\n",
    "\n",
    "Number of Attributes: 24\n",
    "\n",
    "Associated Tasks:\n",
    "\n",
    "Classification\n",
    "\n",
    "Missing Values?\n",
    "\n",
    "N/A\n",
    "\n",
    "Source:\n",
    "\n",
    "Name: I-Cheng Yeh\n",
    "email addresses: (1) icyeh '@' chu.edu.tw (2) 140910 '@' mail.tku.edu.tw\n",
    "institutions: (1) Department of Information Management, Chung Hua University, Taiwan. (2) Department of Civil Engineering, Tamkang University, Taiwan.\n",
    "other contact information: 886-2-26215656 ext. 3181\n",
    "\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel â€œSorting Smoothing Methodâ€ to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "X2: Gender (1 = male; 2 = female).\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "X5: Age (year).\n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data and looking at the first 10 and last 10 rows\n",
    "default = pd.read_csv('C:/Users/fb8502oa/Desktop/Projects using Python/default of credit card clients.csv', header = 1)\n",
    "default.head(10)\n",
    "default.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of the variables are int variables but are supposed to be factor variables.\n",
    "Education, sex, marriage, pay and default payment next month.\n",
    "Let's look at the Education levels for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at default \n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "sb.distplot(default['default payment next month'],kde = False)\n",
    "plt.show()\n",
    "#very few people are likely to default.\n",
    "#data is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remaning the default variable name\n",
    "default.rename(columns={'default payment next month':'DEFAULT'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING TO FIT SKITLEARN FORMAT."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## SEPARATING FEATURES AND ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separeting the education dummy variable features for skitlearn\n",
    "#one-hot encoding for Education\n",
    "default['GRAD_SCHOOL'] = (default['EDUCATION']==1).astype('int')\n",
    "default['UNIVERSITY'] = (default['EDUCATION']==2).astype('int')\n",
    "default['HIGH_SCHOOL'] = (default['EDUCATION']==3).astype('int')\n",
    "default.drop('EDUCATION', axis =1, inplace = True)\n",
    "default.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separeting the sex dummy variable features for skitlearn\n",
    "#one-hot encoding for sex\n",
    "\n",
    "default['MALE']= (default['SEX']==1).astype('int')\n",
    "default.drop('SEX', axis = 1, inplace = True)\n",
    "default.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separeting the married and pay dummy variable features for skitlearn\n",
    "#one-hot encoding for marriage\n",
    "default['MARRIED'] = (default['MARRIAGE']==1).astype('int')\n",
    "default.drop('MARRIAGE', axis=1, inplace = True)\n",
    "default.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with the pay columns. anything less thaN 0 means it was not delayed.\n",
    "#this is an assumption\n",
    "PAY = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for i in PAY:\n",
    "    default.loc[default[i]<=0, i] = 0\n",
    "    \n",
    "default.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.ticker import NullFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at default values so that we know their real classification\n",
    "default['DEFAULT'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default.columns\n",
    "#x variables\n",
    "X = default[['ID', 'LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
    "       'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
    "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'GRAD_SCHOOL',\n",
    "       'UNIVERSITY', 'HIGH_SCHOOL', 'MALE', 'MARRIED']]\n",
    "X[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y variable\n",
    "y = default['DEFAULT'].values\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## NORMALIZE DATA (SCALING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The x variables have values ranging from 0 to some that have more than 1000. \n",
    "#scaling is important\n",
    "X =preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.25, random_state = 2)\n",
    "print('Train set: ', X_train.shape, y_train.shape)\n",
    "print('Test set: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1. K NEAREST NEIGHBOR (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start with k= 2\n",
    "k=2 \n",
    "#model \n",
    "DFneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train)\n",
    "DFneigh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = DFneigh.predict(X_test)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "print('Train set Accuracy: ', metrics.accuracy_score(y_train, DFneigh.predict(X_train)))\n",
    "print('Test set Accuracy: ', metrics.accuracy_score(y_test, yhat))\n",
    "F1_score = f1_score(y_test, yhat, average = 'weighted')\n",
    "print(\"the F1 score is: \", F1_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## finding optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#How i got 7 as the best k \n",
    "ks = 4\n",
    "mean_acc= np.zeros((ks-1))\n",
    "std_acc = np.zeros((ks-1))\n",
    "confusionMx = [];\n",
    "for n in range (1, ks):\n",
    "    #Train model and predict\n",
    "    neighb = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\n",
    "    yhat = neighb.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test,yhat)\n",
    "    \n",
    "    std_acc[n-1] = np.std(yhat == y_test)/np.sqrt(yhat.shape[0])\n",
    "    \n",
    "mean_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#printing the best k \n",
    "print(\"the best accuracy was with \", mean_acc.max(), \"with k = \", mean_acc.argmax()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCURACY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since my model started with the optimal number of k, lets look at the report \n",
    "#the report\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2: DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFtree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4)\n",
    "DFtree\n",
    "\n",
    "#fitting the model \n",
    "DFtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTree = DFtree.predict(X_test)\n",
    "predTree[0:5]\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"DesicionTree's accuracy: \", metrics.accuracy_score(y_test, predTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, predTree)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(y_test, predTree, average='weighted')\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCURACY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for f1 score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, predTree))\n",
    "print(classification_report(y_test, predTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3: SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pylab as pl\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING THE MODEL\n",
    "DFsvm = svm.SVC(kernel = \"rbf\", gamma = 'scale')\n",
    "DFsvm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction \n",
    "yhat1 =DFsvm.predict(X_test)\n",
    "yhat1[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the model usinf sklearn \n",
    "from sklearn import metrics\n",
    "print(\"Accuracy is: \", metrics.accuracy_score(y_test, yhat1))\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat1)\n",
    "\n",
    "\n",
    "#finding the f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(y_test, yhat1, average='weighted')\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report\n",
    "print(classification_report(y_test, yhat1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4: LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libaries\n",
    "import scipy.optimize as opt\n",
    "#the data has already been split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C= 0.01, solver = 'liblinear').fit(X_train, y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction \n",
    "yhat2 = LR.predict(X_test)\n",
    "yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimates for all classes \n",
    "yhat2_prob = LR.predict_proba(X_test)\n",
    "yhat2_prob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY EVALUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#evaluation \n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(y_test, yhat2, average='weighted')\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 5: NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC = GaussianNB()\n",
    "NBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions \n",
    "ypred = NBC.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ACCURACY EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(y_test, ypred, average='weighted')\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve\n",
    "metrics = pd.DataFrame(index=['accuracy', 'precision', 'recall'],\n",
    "                      columns = ['KNNeigh', 'Desc_Trees', 'SVM', 'LogisticReg', 'NaiveB','NeuralNet'])\n",
    "ypred = NBC.predict(X_test)\n",
    "\n",
    "metrics.loc['accuracy', 'NaiveB'] = accuracy_score(ypred, y_test)\n",
    "metrics.loc['precision', 'NaiveB'] = precision_score(ypred, y_test)\n",
    "metrics.loc['recall', 'NaiveB'] = recall_score(ypred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 6: NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries \n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCURACY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE BEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best model is logistic regression with: % metrics\n",
    "\n",
    "Accuracy 82.17%\n",
    "\n",
    "Precision 70%\n",
    "\n",
    "Recall 35%\n",
    "\n",
    "## Naive Bayes has the best recall: % metrics\n",
    "\n",
    "Accuracy 76.85%\n",
    "\n",
    "Precision 57.08%\n",
    "\n",
    "Recall 48.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(y_test,yhat2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Looking for a good threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trying to adjust the model \n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(thresholds_lr, precision_lr[1:], label = 'precision')\n",
    "ax.plot(thresholds_lr, recall_lr[1:], label = 'recall')\n",
    "ax.set_xlabel('Classification threshold')\n",
    "ax.set_ylabel('precision, recall')\n",
    "ax.set_title('LogisticREg: precision recall')\n",
    "ax.hlines(y=0.6, xmin =0, xmax=1, color ='Blue')\n",
    "ax.legend()\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dealing with thres\n",
    "yhatz = LR.predict_proba(X_test)[:,1]\n",
    "ypredtest = (yhatz>=0.25).astype('int')\n",
    "print(classification_report(y_test,ypredtest ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECALL EXPLAINATION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Recall will hold more importance over precision in the case of classifying defaulters, because we want to be able to catch as many potential defaulters as possible so as to not incur losses to the bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION FOR A CUSTOMER.\n",
    "NEW DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW DATA\n",
    "ID = 2\n",
    "LIMIT_BAL= 6000\n",
    "AGE= 24                    \n",
    "BILL_AMT1= 608\n",
    "BILL_AMT2= 57800\n",
    "BILL_AMT3= 500                       \n",
    "BILL_AMT4= 1000\n",
    "BILL_AMT5= 600\n",
    "BILL_AMT6= 1000\n",
    "PAY_AMT1=6000                 \n",
    "PAY_AMT2= 50\n",
    "PAY_AMT3= 0\n",
    "PAY_AMT4= 0\n",
    "PAY_AMT5= 0\n",
    "PAY_AMT6=0\n",
    "MALE=-1\n",
    "GRAD_SCHOOL= 1 \n",
    "UNIVERSITY= 0 \n",
    "HIGH_SCHOOL= 0 \n",
    "MARRIED= 1\n",
    "PAY_0= 0 \n",
    "PAY_2= 0\n",
    "PAY_3= 0 \n",
    "PAY_4= 0 \n",
    "PAY_5= 1\n",
    "PAY_6= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#default.drop('ID', axis =1)\n",
    "prediction = LR.predict([[ID,LIMIT_BAL,AGE,BILL_AMT1,BILL_AMT2,\n",
    "                          BILL_AMT3,BILL_AMT4,BILL_AMT5,\n",
    "                          BILL_AMT6,PAY_AMT1,PAY_AMT2,\n",
    "                          PAY_AMT3,PAY_AMT4,PAY_AMT5,PAY_AMT6,MALE,\n",
    "                          GRAD_SCHOOL, UNIVERSITY,HIGH_SCHOOL,MARRIED,PAY_0,\n",
    "                          PAY_2,PAY_3,PAY_4,PAY_5,PAY_6]])\n",
    "\n",
    "probability = LR.predict_proba([[ID,LIMIT_BAL,AGE,BILL_AMT1,BILL_AMT2,\n",
    "                          BILL_AMT3,BILL_AMT4,BILL_AMT5,\n",
    "                          BILL_AMT6,PAY_AMT1,PAY_AMT2,\n",
    "                          PAY_AMT3,PAY_AMT4,PAY_AMT5,PAY_AMT6,MALE,\n",
    "                          GRAD_SCHOOL, UNIVERSITY,HIGH_SCHOOL,MARRIED,PAY_0,\n",
    "                          PAY_2,PAY_3,PAY_4,PAY_5,PAY_6]])\n",
    "\n",
    "prediction = prediction[0]\n",
    "probability = float(probability[0][1])\n",
    "\n",
    "#features = [ 'LIMIT_BAL' , 'SEX' , 'EDUCATION' , 'MARRIAGE','AGE','PAY_MAX_SCORE','BILL_AV_AMT', 'PAY_AMT_AV', 'AVAILABLE_CRED_PERCENT']\n",
    "#prints predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##trying with another formular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(prediction):\n",
    "    if prediction >=0.25:\n",
    "        return 'will default'\n",
    "    else:\n",
    "        return 'will pay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from matplotlib.ticker import NullFormatter\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "def ind_prediction(newdata):\n",
    "    data = newdata.values.reshape(1,-1)\n",
    "    data = preprocessing.StandardScaler().fit(data).transform(data)\n",
    "    prob = LR.predict_proba(data)[0][1]\n",
    "    if prob >=0.25:\n",
    "        return 'default'\n",
    "    else:\n",
    "        return 'will pay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay = default[default['DEFAULT']==0]\n",
    "pay.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_cust = OrderedDict([('ID', 0),('LIMIT_BAL', 4000), ('AGE', 50), ('BILL_AMT1', 500),\n",
    "                        ('BILL_AMT2',35509), ('BILL_AMT3',689), ('BILL_AMT4', 0), \n",
    "                        ('BILL_AMT5', 0), ('BILL_AMT6',0),('PAY_AMT1',0), ('PAY_AMT2', 35509),\n",
    "                        ('PAY_AMT3', 0), ('PAY_AMT4',0), ('PAY_AMT5',0), ('PAY_AMT6',0),('MALE',1),\n",
    "                        ('GRAD_SCHOOL',0), ('UNIVERSITY',1),\n",
    "                        ('HIGH_SCHOOL',0), ('MARRIED',1), ('PAY_0',-1), ('PAY_2', -1),('PAY_3', -1), \n",
    "                        ('PAY_4',0), ('PAY_5', -1), ('PAY_6',0)])\n",
    "new_cust = pd.Series(new_cust)\n",
    "ind_prediction(new_cust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}